{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cea5fff1"
      },
      "source": [
        "# Import Libraries"
      ],
      "id": "cea5fff1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19570f74"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout , Flatten, BatchNormalization , Conv2D , MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "19570f74"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60mCbsyxQyBf"
      },
      "source": [
        "# Load Data"
      ],
      "id": "60mCbsyxQyBf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjIgd1FgNIc1"
      },
      "outputs": [],
      "source": [
        "(X_train , y_train), (X_test , y_test) = keras.datasets.cifar10.load_data()"
      ],
      "id": "cjIgd1FgNIc1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPd6XS8JQ0R3"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "id": "tPd6XS8JQ0R3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MiIg3hPXAvK"
      },
      "outputs": [],
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "0MiIg3hPXAvK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEjyKPU9Q0T0"
      },
      "outputs": [],
      "source": [
        "# plot first few images\n",
        "for i in range(9):\n",
        "    plt.subplot(331 + i)\n",
        "    plt.imshow(X_train[i])"
      ],
      "id": "DEjyKPU9Q0T0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7261442c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 0 --> 255.\n",
        "X_train[0]"
      ],
      "id": "7261442c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq6q-d0fW5FV"
      },
      "outputs": [],
      "source": [
        "# Rescale Input\n",
        "X_train = X_train/255\n",
        "X_test  = X_test/255"
      ],
      "id": "mq6q-d0fW5FV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ91JlaNd9F2"
      },
      "outputs": [],
      "source": [
        "# to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test  = to_categorical(y_test)"
      ],
      "id": "qZ91JlaNd9F2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XBgDQLOez6r"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ],
      "id": "7XBgDQLOez6r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gacYsmB-opCf"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ],
      "id": "gacYsmB-opCf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5H7o2wlSduq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_data(data_set):\n",
        "    # preprocess_data\n",
        "    return data_set\n",
        "\n",
        "# X_train = preprocess_data(X_train)\n",
        "# X_test  = preprocess_data(X_test)"
      ],
      "id": "g5H7o2wlSduq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnfEwoR_TlBa"
      },
      "outputs": [],
      "source": [
        "X_train.max(), X_train.min()"
      ],
      "id": "FnfEwoR_TlBa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gptfORN3Q0Xn"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE  = 64\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS      = 50"
      ],
      "id": "gptfORN3Q0Xn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ce6622"
      },
      "source": [
        "# Assignment 01\n",
        "- Design your own `deep NN` to classify the `CIFAR 10` images (you can download from keras.dataset) into one of the 10 classes\n",
        "- Investigate the use of different architectures (`different layers`, `learning rate`, `optimizers`, `loss function`)\n",
        "- Note you will need to `flatten` the image and use it as your input vector"
      ],
      "id": "97ce6622"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d4e11b3"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ],
      "id": "7d4e11b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX9HO5s9uBWb"
      },
      "outputs": [],
      "source": [
        "X_train.shape[1:] # 32 x 32 x 3  --> 3072"
      ],
      "id": "vX9HO5s9uBWb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb0415df"
      },
      "outputs": [],
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Flatten(input_shape=(X_train.shape[1:])))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Dense(256,activation='elu'))\n",
        "model_1.add(Dropout(0.37))\n",
        "model_1.add(Dense(256,activation='elu'))\n",
        "model_1.add(Dropout(0.37))\n",
        "model_1.add(Dense(NUM_CLASSES,activation='softmax'))\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy'\n",
        "               ,optimizer=keras.optimizers.Adamax()\n",
        "               ,metrics=['accuracy'])\n",
        "\n",
        "model_1.summary()"
      ],
      "id": "eb0415df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ctxB7WNOCB",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history_1 = model_1.fit(X_train , y_train ,\n",
        "                       epochs = EPOCHS,\n",
        "                       batch_size= BATCH_SIZE,\n",
        "                       validation_split = 0.1)"
      ],
      "id": "F_ctxB7WNOCB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEOhIs-wNODc"
      },
      "outputs": [],
      "source": [
        "model_1.metrics_names"
      ],
      "id": "TEOhIs-wNODc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z3t35dTNOHE"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(X_train , y_train)\n"
      ],
      "id": "-z3t35dTNOHE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqrPlREqUbt5"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(X_test , y_test)"
      ],
      "id": "gqrPlREqUbt5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMK2fL-6UZZs"
      },
      "outputs": [],
      "source": [
        "# Plot the training accuracy and loss\n",
        "fig = plt.figure(figsize = (20, 15))\n",
        "ax = fig.subplots(nrows = 1 , ncols = 2)\n",
        "\n",
        "ax[0].plot(history_1.history['accuracy'] , label ='Train')\n",
        "ax[0].plot(history_1.history['val_accuracy'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Accuracy Performance')\n",
        "\n",
        "ax[1].plot(history_1.history['loss'] , label ='Train')\n",
        "ax[1].plot(history_1.history['val_loss'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Loss Performance')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "id": "BMK2fL-6UZZs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cc7ddb1"
      },
      "source": [
        "# Assignment 02\n",
        "- Design your `deep convolutional neural network` ( to classify the `CIFAR 10` images into one of the 10 classes\n",
        "- Invistage the use of different architectures (different `layers`, `kernel sizes`, `pooling`, `learning rate`, `optimizers`, `loss function`)"
      ],
      "id": "7cc7ddb1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a59b51af"
      },
      "source": [
        "You have to specify filters and kernel_size. These parameters have no default.\n",
        "\n",
        "Default padding is valid, which means no zero-padding, and the default strides is (1,1).\n",
        "\n",
        "# (N - F + 2P)/S   +  1\n",
        "\n",
        "# P =  (F - 1) / 2"
      ],
      "id": "a59b51af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMrROI5eYJZ2"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten"
      ],
      "id": "nMrROI5eYJZ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29c77545"
      },
      "outputs": [],
      "source": [
        "X_train.shape[1:]"
      ],
      "id": "29c77545"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdc5c25e"
      },
      "outputs": [],
      "source": [
        "# model2 = Sequential()\n",
        "\n",
        "# model2.add(Conv2D(256 , (3 , 3) , padding= 'same' , input_shape = X_train.shape[1:]))\n",
        "# model2.add(BatchNormalization())\n",
        "# model2.add(Conv2D(128 , (3, 3)))\n",
        "# model2.add(BatchNormalization())\n",
        "# model2.add(MaxPooling2D(pool_size = (2,2)))\n",
        "# model2.add(Dropout(0.4))\n",
        "\n",
        "# model2.add(Conv2D(256 , (3 , 3) , padding= 'same' , input_shape = X_train.shape[1:]))\n",
        "# model2.add(BatchNormalization())\n",
        "# model2.add(Conv2D(128 , (3, 3)))\n",
        "# model2.add(BatchNormalization())\n",
        "# model2.add(MaxPooling2D(pool_size = (2,2)))\n",
        "# model2.add(Dropout(0.4))\n",
        "\n",
        "# model2.add(Flatten())\n",
        "# model2.add(Dense(512))\n",
        "# model2.add(Dropout(0.3))\n",
        "\n",
        "# model2.add(Dense(10 , activation = 'softmax'))\n",
        "# model2.compile(loss = 'categorical_crossentropy' , \n",
        "#                optimizer = keras.optimizers.Adam() ,\n",
        "#                metrics = ['accuracy'])\n",
        "# model2.summary()\n"
      ],
      "id": "cdc5c25e"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MaxPool2D"
      ],
      "metadata": {
        "id": "ZVs3U2ypSB0W"
      },
      "id": "ZVs3U2ypSB0W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D((2, 2)))\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D((2, 2)))\n",
        "model2.add(Dropout(0.4))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "# opt = SGD(lr=0.001, momentum=0.9)\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "Oco1C2naR0E4"
      },
      "id": "Oco1C2naR0E4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "741af05e"
      },
      "outputs": [],
      "source": [
        "history_2 = model2.fit(X_train , y_train , \n",
        "                       epochs = EPOCHS ,\n",
        "                       batch_size = 64,\n",
        "                       validation_split = 0.1)"
      ],
      "id": "741af05e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQCW0XKbaJYk"
      },
      "outputs": [],
      "source": [
        "model2.metrics_names"
      ],
      "id": "GQCW0XKbaJYk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw3iS5V_aM5Z"
      },
      "outputs": [],
      "source": [
        "model2.evaluate(X_train , y_train)"
      ],
      "id": "Mw3iS5V_aM5Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIYkhuqdaM8R"
      },
      "outputs": [],
      "source": [
        "model2.evaluate(X_test , y_test)"
      ],
      "id": "yIYkhuqdaM8R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwLmUFFwaSLV"
      },
      "outputs": [],
      "source": [
        "# Plot the training accuracy and loss\n",
        "\n",
        "# Plot the training accuracy and loss\n",
        "fig = plt.figure(figsize = (20, 15))\n",
        "ax = fig.subplots(nrows = 1 , ncols = 2)\n",
        "\n",
        "ax[0].plot(history_2.history['accuracy'] , label ='Train')\n",
        "ax[0].plot(history_2.history['val_accuracy'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Accuracy Performance')\n",
        "\n",
        "ax[1].plot(history_2.history['loss'] , label ='Train')\n",
        "ax[1].plot(history_2.history['val_loss'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Loss Performance')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()\n"
      ],
      "id": "bwLmUFFwaSLV"
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model_2.add(Conv2D(32, (3, 3), padding='same',input_shape=X_train.shape[1:]))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Conv2D(32, (3, 3)))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Conv2D(64, (3, 3)))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "# FLATTERN => DENSE => RELU => DROPOUT\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(512))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "# a softmax classifier\n",
        "model_2.add(Dense(NUM_CLASSES))\n",
        "model_2.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "id": "c1ASsbWkMmge"
      },
      "id": "c1ASsbWkMmge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8xXUBQEY2WJ"
      },
      "outputs": [],
      "source": [
        "history2 = model_2.fit(X_train , y_train , \n",
        "                       epochs = EPOCHS ,\n",
        "                       batch_size = 64,\n",
        "                       validation_split = 0.1)"
      ],
      "id": "T8xXUBQEY2WJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUY9pvmWaVQu"
      },
      "outputs": [],
      "source": [
        "model2.metrics_names"
      ],
      "id": "GUY9pvmWaVQu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4FjPayLgBL1"
      },
      "outputs": [],
      "source": [
        "model2.evaluate(X_train , y_train)"
      ],
      "id": "j4FjPayLgBL1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb7xLbhJgBOm"
      },
      "outputs": [],
      "source": [
        "model2.evaluate(X_test , y_test)"
      ],
      "id": "Fb7xLbhJgBOm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ea964bc"
      },
      "source": [
        "---"
      ],
      "id": "9ea964bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69001823"
      },
      "source": [
        "# Assignment 03\n",
        "- Repeat Assignment 1 and 2 using MNIST dataset\n",
        "- Note that you will need to convert the training labels into categorical using one hot encoding using `to_categorical()` function"
      ],
      "id": "69001823"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_gDUUQnVTBB"
      },
      "source": [
        "# Load Data"
      ],
      "id": "h_gDUUQnVTBB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9CbKkofVTBD"
      },
      "outputs": [],
      "source": [
        "(X_train , y_train), (X_test , y_test) = keras.datasets.mnist.load_data()"
      ],
      "id": "S9CbKkofVTBD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhIr9-YtVTBD"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "id": "IhIr9-YtVTBD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpLmksCfV-zY"
      },
      "outputs": [],
      "source": [
        "print(y_train.shape)\n",
        "y_train"
      ],
      "id": "YpLmksCfV-zY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG_3IDIuVeHv"
      },
      "outputs": [],
      "source": [
        "# OR use 'sparse_categorical_crossentropy' in the [LOSS Function]\n"
      ],
      "id": "UG_3IDIuVeHv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70jNtzg5l32O"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ],
      "id": "70jNtzg5l32O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKt9SdB7WZ_B"
      },
      "outputs": [],
      "source": [
        "y_train"
      ],
      "id": "nKt9SdB7WZ_B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg8G-cqo12X6"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ],
      "id": "Lg8G-cqo12X6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtUJUKWUVTBE"
      },
      "outputs": [],
      "source": [
        "# plot first few images\n",
        "for i in range(9):\n",
        "    plt.subplot(331 + i)\n",
        "    plt.imshow(X_train[i])\n"
      ],
      "id": "BtUJUKWUVTBE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ijmObVTWgdd"
      },
      "outputs": [],
      "source": [
        "# Rescale the Input\n",
        "X_train = X_train/255\n",
        "X_test  = X_test/255"
      ],
      "id": "7ijmObVTWgdd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jn7WxJLWtX2"
      },
      "outputs": [],
      "source": [
        "X_train.max(), X_train.min()"
      ],
      "id": "5jn7WxJLWtX2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze-XxrjWVTBG"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE  = 64\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS      = 50"
      ],
      "id": "ze-XxrjWVTBG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b78b7b07"
      },
      "source": [
        "### ANN "
      ],
      "id": "b78b7b07"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJqDGhAygPTH"
      },
      "outputs": [],
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Flatten(input_shape=(X_train.shape[1:])))\n",
        "model3.add(Dense(128,activation='relu'))\n",
        "model3.add(Dense(128,activation='relu'))\n",
        "model3.add(Dense(NUM_CLASSES , activation='softmax'))\n",
        "\n",
        "\n",
        "model3.compile(loss='sparse_categorical_crossentropy'\n",
        "               ,optimizer=keras.optimizers.Adam()\n",
        "               ,metrics=['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "id": "zJqDGhAygPTH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNfWK640gPTI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history_3 = model3.fit(X_train , y_train ,\n",
        "                       epochs = EPOCHS,\n",
        "                       batch_size= BATCH_SIZE,\n",
        "                       validation_split = 0.1)"
      ],
      "id": "VNfWK640gPTI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ4AIKvmgPTJ"
      },
      "outputs": [],
      "source": [
        "model3.metrics_names"
      ],
      "id": "wZ4AIKvmgPTJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqq_TPlZgPTM"
      },
      "outputs": [],
      "source": [
        "model3.evaluate(X_train , y_train)"
      ],
      "id": "aqq_TPlZgPTM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z86fThpvgPTL"
      },
      "outputs": [],
      "source": [
        "model3.evaluate(X_test , y_test)"
      ],
      "id": "Z86fThpvgPTL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZZxcWcJJ7OT"
      },
      "outputs": [],
      "source": [
        "# Plot the training accuracy and loss\n",
        "fig = plt.figure(figsize = (20, 15))\n",
        "ax = fig.subplots(nrows = 1 , ncols = 2)\n",
        "\n",
        "ax[0].plot(history_3.history['accuracy'] , label ='Train')\n",
        "ax[0].plot(history_3.history['val_accuracy'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Accuracy Performance')\n",
        "\n",
        "ax[1].plot(history_3.history['loss'] , label ='Train')\n",
        "ax[1].plot(history_3.history['val_loss'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Loss Performance')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()\n"
      ],
      "id": "FZZxcWcJJ7OT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2GjPQ9AgPTM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "O2GjPQ9AgPTM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a8c92e4"
      },
      "outputs": [],
      "source": [
        "# to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test  = to_categorical(y_test)"
      ],
      "id": "0a8c92e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43802ec0"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ],
      "id": "43802ec0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c151f2d3"
      },
      "source": [
        "### CNN "
      ],
      "id": "c151f2d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJAp-eFXB_wk"
      },
      "outputs": [],
      "source": [
        "(X_train , y_train), (X_test , y_test) = keras.datasets.mnist.load_data()"
      ],
      "id": "XJAp-eFXB_wk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTk_Z32hKlJd"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "X_test = X_test.reshape(-1 , 28 , 28 , 1)"
      ],
      "id": "FTk_Z32hKlJd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b395cbb7"
      },
      "outputs": [],
      "source": [
        "X_train.shape[1:]"
      ],
      "id": "b395cbb7"
    },
    {
      "cell_type": "code",
      "source": [
        "# to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test  = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "nC0qJSz69VU0"
      },
      "id": "nC0qJSz69VU0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QJ2mqG83znc"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ],
      "id": "7QJ2mqG83znc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpOS8jLxAXY8"
      },
      "outputs": [],
      "source": [
        "model_4 = Sequential()\n",
        "model_4.add(Conv2D(16, (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model_4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_4.add(Flatten())\n",
        "\n",
        "\n",
        "model_4.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
        "\n",
        "model_4.compile(loss='categorical_crossentropy', \n",
        "                    optimizer=keras.optimizers.Adam(),  \n",
        "                    metrics=['accuracy'])\n",
        "model_4.summary()"
      ],
      "id": "FpOS8jLxAXY8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY6dEaKQAfmu"
      },
      "outputs": [],
      "source": [
        "history_4 = model_4.fit(X_train , y_train , \n",
        "                       epochs = EPOCHS ,\n",
        "                       batch_size = 64,\n",
        "                       validation_split = 0.1)"
      ],
      "id": "jY6dEaKQAfmu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z81tq14jgmTA"
      },
      "outputs": [],
      "source": [
        "model_4.metrics_names"
      ],
      "id": "Z81tq14jgmTA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPd20cUHgmTC"
      },
      "outputs": [],
      "source": [
        "model_4.evaluate(X_train , y_train)"
      ],
      "id": "fPd20cUHgmTC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiNf_7KtgmTB"
      },
      "outputs": [],
      "source": [
        "model_4.evaluate(X_test , y_test)"
      ],
      "id": "QiNf_7KtgmTB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzwv41F2gmTD"
      },
      "outputs": [],
      "source": [
        "# Plot the training accuracy and loss\n",
        "fig = plt.figure(figsize = (20, 15))\n",
        "ax = fig.subplots(nrows = 1 , ncols = 2)\n",
        "\n",
        "ax[0].plot(history_4.history['accuracy'] , label ='Train')\n",
        "ax[0].plot(history_4.history['val_accuracy'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Accuracy Performance')\n",
        "\n",
        "ax[1].plot(history_4.history['loss'] , label ='Train')\n",
        "ax[1].plot(history_4.history['val_loss'] , label ='Validation')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_title('Loss Performance')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()\n"
      ],
      "id": "lzwv41F2gmTD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6nylCXk4QPz"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "n6nylCXk4QPz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E8FpZs14QjU"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "-E8FpZs14QjU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFTiuxE958dV"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "aFTiuxE958dV"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7cc7ddb1",
        "69001823"
      ],
      "name": "Lab_02_and_03_Mohamed Ibrahem.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}